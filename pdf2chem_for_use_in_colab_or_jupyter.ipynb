{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "vsAO7yruXlg_"
   },
   "source": [
    "# Introductory text and instructions\n",
    "\n",
    "The pdf2chem code extracts known chemicals mentioned in pdf files and outputs a csv with the machine readable SMILES format, making it easy to populate a chemical database from a set of pdfs.  If you curate multiple pdf files, this code will also output a csv file with all chemicals found in that session.\n",
    "___\n",
    "\n",
    "**Click the small folder icon** at the left of your screen.  That should connect this page to a hosted runtime and open up a file browser for you.  (At the time of this writing, it contains a folder called sample_data.  That's material from Google, and you can ignore it for this code.)\n",
    "\n",
    "Please **drag or otherwise upload the pdf(s) you'd like to curate into the hosted file browser at the left of your screen**.  If you need a pdf to try it with, [here's a link](https://pubs.acs.org/doi/pdf/10.1021/acs.jpcb.8b12322) to one that's open access.  Then, if you'd like your search to include 3-letter words, select \"exhaustive\" from the dropdown input below.  Note that this is likely to increase the number of false positive results, chemicals that weren't mentioned in the paper.\n",
    "\n",
    "Finally, go to the runtime menu and **click \"run all\"**.  If you **scroll down** to the last cell, you'll be able to watch the results trickle in as the program runs.  Note: the imports section takes a minute or two to download everything it needs before it starts in earnest.\n",
    "\n",
    "After it finishes, wait a few seconds, and csv files of the results will populate the file browser at the left.  You can then right-click them to download them to your computer.  If you change the dropdown choice or upload new files after a run, please click \"run all\" again to run the updated code."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "cellView": "form",
    "executionInfo": {
     "elapsed": 469,
     "status": "ok",
     "timestamp": 1617212199118,
     "user": {
      "displayName": "John Goeltz",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14Gj3FhUN6-o1CQ5sALSoVIN_uvhDla_H5orAz1El=s64",
      "userId": "06562502469486255027"
     },
     "user_tz": 420
    },
    "id": "uR8s7cczycqo"
   },
   "outputs": [],
   "source": [
    "#@title ## Please select the desired style of curation\n",
    "#@markdown The default style is \"regular\", which will ignore 3-letter words and result in fewer \"false positives,\" chemicals that were not actually mentioned in the pdf\n",
    "\n",
    "curation_type = \"Regular (ignores 3-letter words)\" #@param [\"Regular (ignores 3-letter words)\", \"Exhaustive (includes 3-letter words)\"]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "OP0GAVN_Xmq4"
   },
   "source": [
    "# Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 0
    },
    "executionInfo": {
     "elapsed": 67128,
     "status": "ok",
     "timestamp": 1617212265784,
     "user": {
      "displayName": "John Goeltz",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14Gj3FhUN6-o1CQ5sALSoVIN_uvhDla_H5orAz1El=s64",
      "userId": "06562502469486255027"
     },
     "user_tz": 420
    },
    "id": "VffJT09g92lX",
    "outputId": "b912f199-2e8e-4302-b7a3-13408f405fd4"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: chemdataextractor in c:\\users\\jgoel\\anaconda3\\lib\\site-packages (1.3.0)\n",
      "Requirement already satisfied: lxml in c:\\users\\jgoel\\anaconda3\\lib\\site-packages (from chemdataextractor) (4.6.2)\n",
      "Requirement already satisfied: python-crfsuite in c:\\users\\jgoel\\anaconda3\\lib\\site-packages (from chemdataextractor) (0.9.7)\n",
      "Requirement already satisfied: DAWG in c:\\users\\jgoel\\anaconda3\\lib\\site-packages (from chemdataextractor) (0.8.0)\n",
      "Requirement already satisfied: PyYAML in c:\\users\\jgoel\\anaconda3\\lib\\site-packages (from chemdataextractor) (5.4.1)\n",
      "Requirement already satisfied: requests in c:\\users\\jgoel\\anaconda3\\lib\\site-packages (from chemdataextractor) (2.25.1)\n",
      "Requirement already satisfied: six in c:\\users\\jgoel\\anaconda3\\lib\\site-packages (from chemdataextractor) (1.15.0)\n",
      "Requirement already satisfied: beautifulsoup4 in c:\\users\\jgoel\\anaconda3\\lib\\site-packages (from chemdataextractor) (4.8.0)\n",
      "Requirement already satisfied: python-dateutil in c:\\users\\jgoel\\anaconda3\\lib\\site-packages (from chemdataextractor) (2.8.1)\n",
      "Requirement already satisfied: cssselect in c:\\users\\jgoel\\anaconda3\\lib\\site-packages (from chemdataextractor) (1.1.0)\n",
      "Requirement already satisfied: click in c:\\users\\jgoel\\anaconda3\\lib\\site-packages (from chemdataextractor) (7.1.2)\n",
      "Requirement already satisfied: pdfminer.six in c:\\users\\jgoel\\anaconda3\\lib\\site-packages (from chemdataextractor) (20181108)\n",
      "Requirement already satisfied: nltk in c:\\users\\jgoel\\anaconda3\\lib\\site-packages (from chemdataextractor) (3.5)\n",
      "Requirement already satisfied: appdirs in c:\\users\\jgoel\\anaconda3\\lib\\site-packages (from chemdataextractor) (1.4.4)\n",
      "Requirement already satisfied: soupsieve>=1.2 in c:\\users\\jgoel\\anaconda3\\lib\\site-packages (from beautifulsoup4->chemdataextractor) (2.2)\n",
      "Requirement already satisfied: tqdm in c:\\users\\jgoel\\anaconda3\\lib\\site-packages (from nltk->chemdataextractor) (4.56.0)\n",
      "Requirement already satisfied: joblib in c:\\users\\jgoel\\anaconda3\\lib\\site-packages (from nltk->chemdataextractor) (1.0.1)\n",
      "Requirement already satisfied: regex in c:\\users\\jgoel\\anaconda3\\lib\\site-packages (from nltk->chemdataextractor) (2020.11.13)\n",
      "Requirement already satisfied: sortedcontainers in c:\\users\\jgoel\\anaconda3\\lib\\site-packages (from pdfminer.six->chemdataextractor) (2.3.0)\n",
      "Requirement already satisfied: pycryptodome in c:\\users\\jgoel\\anaconda3\\lib\\site-packages (from pdfminer.six->chemdataextractor) (3.9.9)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in c:\\users\\jgoel\\anaconda3\\lib\\site-packages (from requests->chemdataextractor) (1.26.3)\n",
      "Requirement already satisfied: chardet<5,>=3.0.2 in c:\\users\\jgoel\\anaconda3\\lib\\site-packages (from requests->chemdataextractor) (3.0.4)\n",
      "Requirement already satisfied: idna<3,>=2.5 in c:\\users\\jgoel\\anaconda3\\lib\\site-packages (from requests->chemdataextractor) (2.10)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\jgoel\\anaconda3\\lib\\site-packages (from requests->chemdataextractor) (2020.12.5)\n",
      "Successfully downloaded 0 new data packages (18 existing)\n",
      "Requirement already satisfied: cirpy in c:\\users\\jgoel\\anaconda3\\lib\\site-packages (1.0.2)\n",
      "Requirement already satisfied: textract in c:\\users\\jgoel\\anaconda3\\lib\\site-packages (1.6.3)\n",
      "Requirement already satisfied: pdfminer.six==20181108 in c:\\users\\jgoel\\anaconda3\\lib\\site-packages (from textract) (20181108)\n",
      "Requirement already satisfied: chardet==3.0.4 in c:\\users\\jgoel\\anaconda3\\lib\\site-packages (from textract) (3.0.4)\n",
      "Requirement already satisfied: beautifulsoup4==4.8.0 in c:\\users\\jgoel\\anaconda3\\lib\\site-packages (from textract) (4.8.0)\n",
      "Collecting six==1.12.0\n",
      "  Using cached six-1.12.0-py2.py3-none-any.whl (10 kB)\n",
      "Requirement already satisfied: SpeechRecognition==3.8.1 in c:\\users\\jgoel\\anaconda3\\lib\\site-packages (from textract) (3.8.1)\n",
      "Requirement already satisfied: extract-msg==0.23.1 in c:\\users\\jgoel\\anaconda3\\lib\\site-packages (from textract) (0.23.1)\n",
      "Requirement already satisfied: python-pptx==0.6.18 in c:\\users\\jgoel\\anaconda3\\lib\\site-packages (from textract) (0.6.18)\n",
      "Requirement already satisfied: EbookLib==0.17.1 in c:\\users\\jgoel\\anaconda3\\lib\\site-packages (from textract) (0.17.1)\n",
      "Requirement already satisfied: argcomplete==1.10.0 in c:\\users\\jgoel\\anaconda3\\lib\\site-packages (from textract) (1.10.0)\n",
      "Requirement already satisfied: xlrd==1.2.0 in c:\\users\\jgoel\\anaconda3\\lib\\site-packages (from textract) (1.2.0)\n",
      "Requirement already satisfied: docx2txt==0.8 in c:\\users\\jgoel\\anaconda3\\lib\\site-packages (from textract) (0.8)\n",
      "Requirement already satisfied: soupsieve>=1.2 in c:\\users\\jgoel\\anaconda3\\lib\\site-packages (from beautifulsoup4==4.8.0->textract) (2.2)\n",
      "Requirement already satisfied: lxml in c:\\users\\jgoel\\anaconda3\\lib\\site-packages (from EbookLib==0.17.1->textract) (4.6.2)\n",
      "Requirement already satisfied: tzlocal==1.5.1 in c:\\users\\jgoel\\anaconda3\\lib\\site-packages (from extract-msg==0.23.1->textract) (1.5.1)\n",
      "Requirement already satisfied: olefile==0.46 in c:\\users\\jgoel\\anaconda3\\lib\\site-packages (from extract-msg==0.23.1->textract) (0.46)\n",
      "Requirement already satisfied: imapclient==2.1.0 in c:\\users\\jgoel\\anaconda3\\lib\\site-packages (from extract-msg==0.23.1->textract) (2.1.0)\n",
      "Requirement already satisfied: sortedcontainers in c:\\users\\jgoel\\anaconda3\\lib\\site-packages (from pdfminer.six==20181108->textract) (2.3.0)\n",
      "Requirement already satisfied: pycryptodome in c:\\users\\jgoel\\anaconda3\\lib\\site-packages (from pdfminer.six==20181108->textract) (3.9.9)\n",
      "Requirement already satisfied: XlsxWriter>=0.5.7 in c:\\users\\jgoel\\anaconda3\\lib\\site-packages (from python-pptx==0.6.18->textract) (1.3.7)\n",
      "Requirement already satisfied: Pillow>=3.3.2 in c:\\users\\jgoel\\anaconda3\\lib\\site-packages (from python-pptx==0.6.18->textract) (8.1.1)\n",
      "Requirement already satisfied: pytz in c:\\users\\jgoel\\anaconda3\\lib\\site-packages (from tzlocal==1.5.1->extract-msg==0.23.1->textract) (2021.1)\n",
      "Installing collected packages: six\n",
      "  Attempting uninstall: six\n",
      "    Found existing installation: six 1.15.0\n",
      "    Uninstalling six-1.15.0:\n",
      "      Successfully uninstalled six-1.15.0\n",
      "Successfully installed six-1.12.0\n",
      "We'll use pdftotext as the pdf extraction method.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
      "tensorflow 2.4.1 requires six~=1.15.0, but you have six 1.12.0 which is incompatible.\n"
     ]
    }
   ],
   "source": [
    "!pip install chemdataextractor\n",
    "import chemdataextractor as cde\n",
    "!cde data download\n",
    "\n",
    "!pip install cirpy\n",
    "import cirpy\n",
    "import time\n",
    "\n",
    "import re\n",
    "import pandas as pd\n",
    "import os\n",
    "!pip install textract\n",
    "import textract\n",
    "\n",
    "from datetime import datetime\n",
    "\n",
    "if curation_type == \"Regular (ignores 3-letter words)\":\n",
    "    regex_number = 4\n",
    "else:\n",
    "    regex_number = 3\n",
    "\n",
    "import sys\n",
    "IN_COLAB = \"google.colab\" in sys.modules\n",
    "\n",
    "if IN_COLAB:\n",
    "    pdf_method = \"pdfminer\"\n",
    "else:\n",
    "    pdf_method = \"pdftotext\"\n",
    "\n",
    "print(\"We\\'ll use {} as the pdf extraction method.\".format(pdf_method))\n",
    "\n",
    "# hard-coded list until permanent hosting obtained\n",
    "element_symbols = ['h', 'he', 'li', 'be', 'b', 'c', 'n', 'o', 'f', 'ne', 'na',\n",
    "                   'mg', 'al', 'si', 'p', 's', 'cl', 'ar', 'k', 'ca', 'sc',\n",
    "                   'ti', 'v', 'cr', 'mn', 'fe', 'co', 'ni', 'cu', 'zn', 'ga',\n",
    "                   'ge', 'as', 'se', 'br', 'kr', 'rb', 'sr', 'y', 'zr', 'nb',\n",
    "                   'mo', 'tc', 'ru', 'rh', 'pd', 'ag', 'cd', 'in', 'sn', 'sb',\n",
    "                   'te', 'i', 'xe', 'cs', 'ba', 'la', 'ce', 'pr', 'nd', 'pm',\n",
    "                   'sm', 'eu', 'gd', 'tb', 'dy', 'ho', 'er', 'tm', 'yb', 'lu',\n",
    "                   'hf', 'ta', 'w', 're', 'os', 'ir', 'pt', 'au', 'hg', 'tl',\n",
    "                   'pb', 'bi', 'po', 'at', 'rn', 'fr', 'ra', 'ac', 'th', 'pa',\n",
    "                   'u', 'np', 'pu', 'am', 'cm', 'bk', 'cf', 'es', 'fm', 'md',\n",
    "                   'no', 'lr', 'rf', 'db', 'sg', 'bh', 'hs', 'mt', 'ds ',\n",
    "                   'rg ', 'cn ', 'nh', 'fl', 'mc', 'lv', 'ts', 'og']\n",
    "\n",
    "# hard-coded list until permanent hosting obtained\n",
    "false_positives = ['reno', 'lower', 'format', 'lead', 'nci', 'cc', 'isi',\n",
    "                   'doi', \"\\\\'b\", 'is', 'ph', 'mv', 'zone', 'based', 'on',\n",
    "                   'final', 'kato', 'cm', 'life', 'versus', 'www', 'can',\n",
    "                   'ate', 'mm', 'crystal', 'sem', 'an', 's1', 'force', 'may',\n",
    "                   'any', 'lau', 'voltage', 'kc', 'mino', 'm. h.', 'set',\n",
    "                   'selective', 'c.p.k.', 'same', 'page 10', 'm-1', 'ai',\n",
    "                   'c1', 'm2', 'et', 'fulfill', 'dry', 'via', 'may', 'pka',\n",
    "                   'any', 'edge', 'b.v.', 'final', 'rt', '2b', 'h.y.', 'y.k.',\n",
    "                   'v.v.', 'w.y.', 'good', 'region', 'cycle', 'des', 'force',\n",
    "                   'may', 'dsc', 'chcl', 'counter', 'van', 'see', 'best',\n",
    "                   'green', 'equal', 'result', 'challenge', 'substance',\n",
    "                   'spectrum', 'der', 'its', 'glass', 'all', 'new', 'mix',\n",
    "                   'so', 'soc.', 'arm', 'nm', 'ran', 'enable', 'sd', 'saa',\n",
    "                   'map', 'ac1', 'fab', 'act', 'b7', 'liu', 'check', 'dual',\n",
    "                   'via', 'den', 'fc', 'if', 'rapid', 'san', 'van',\n",
    "                   'control', 'see', 'harry', 'adam', 'line', 'ac-1',\n",
    "                   'sig', 'recruit', 'bli', 'test', 'tau', 'acs', 'iap',\n",
    "                   'box', 'campaign', 'target', 'gfp', 'new', 'cv', 'rt',\n",
    "                   'lid', 'compound', 'selective', 'rfb', 'ment', 'est',\n",
    "                   'mm', 'con', 'con-', 's4', 'harry', 'ip', 'lp', 'ple',\n",
    "                   'ml', 'prone', 'pka', 'sum', 'derivative', 'ten', 'min',\n",
    "                   'vortex', 'gradual', 'tot', 'ber', 'red', 'ing', 'para',\n",
    "                   'phs', 'gen', 'dft', 'nals', 'enable', 'set', 'versus',\n",
    "                   'ma', 'the', 'and', 'eo', 'cps', 'ep', 'are', 'same',\n",
    "                   'cos', 'age', 'sem', 's4', 'cycle', 'far', 'cal',\n",
    "                   'overall', 'net', 'et', 'ml', 's1', 'prone', 'capture',\n",
    "                   'or', 'rise', 'but', 'diurnal', 'dry', 'may', 'of', 'off',\n",
    "                   'dp', 'if', 'dants', 'van', 'eden', 'line', 'tx', 'top',\n",
    "                   'va', 'per', 'ny', 'on', 'ing', 'cp', 'for', 'dc', 'air',\n",
    "                   'nhe', 'gas', 'zonal', 'all', 'new', 'based', 'had', 'ph',\n",
    "                   'cm3', 'pyrite', 'soc', 'ser', 'acc', 'res', 'eds', 'mp',\n",
    "                   'pro', 'inc', 'im', 'bv', 'disodium', 'ab', 'ed',\n",
    "                   'carboxylate', '1mm', 'nat', 'eq', 'acc', 'sci', 'mol',\n",
    "                   'int', 'sc-s', 'scs', 'gu', 'atm', 'shi', '2az', 'abbott',\n",
    "                   'ms', 'wang', 'pdc', 'franklin', 'bay', 'dess', 'hbd',\n",
    "                   'retard', 'intercept', 'iii', 'acid', 'fraction',\n",
    "                   'aldrich', 'triton', 'cda', 'cyano', 'vinyl', 'flux',\n",
    "                   'ethyl', 'methyl', 'mit', 'trigger', 'accelerate', 'ants',\n",
    "                   'pentyl', 'laser', 'india', 'dos', 'los', 'acetyl', 'dec',\n",
    "                   'sheets', 'tem', 'dimethyl', 'serial', 'tag', 'tandem',\n",
    "                   'trap', 'mic', 'exciton', 'aldehyde', 'combat', 'roi',\n",
    "                   'probiotic', 'antiviral', 'cada', 'beam', 'austin',\n",
    "                   'lactone', 'lumen', 'diethyl', 'optimal', 'sulfoxide',\n",
    "                   'gm3', 'gel', 'blockade', 'omega', 'cubes', 'bin',\n",
    "                   'alcohols', 'alcohol', 'benchmark', 'portal', 'matrix',\n",
    "                   'apex', 'bacterial', 'cube', 'linker', 'cascade',\n",
    "                   'optimum', 'carbonyl oxygen', 'facet', 'shield']\n",
    "\n",
    "if regex_number == 3:\n",
    "    false_positives = [word for word in false_positives if not\n",
    "                       re.search(\"[a-zA-Z0-9+-]{3}\", word) or\n",
    "                       re.search(\"[a-zA-Z0-9+-]{4}\", word)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "OR4Mk87oX0IM"
   },
   "source": [
    "# Define functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "executionInfo": {
     "elapsed": 67313,
     "status": "ok",
     "timestamp": 1617212265976,
     "user": {
      "displayName": "John Goeltz",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14Gj3FhUN6-o1CQ5sALSoVIN_uvhDla_H5orAz1El=s64",
      "userId": "06562502469486255027"
     },
     "user_tz": 420
    },
    "id": "0sJiR8yw_De_"
   },
   "outputs": [],
   "source": [
    "def quick_curate(pdf_path, pdf_method, false_positives, regex_number):\n",
    "\n",
    "    # extract the text from the pdf\n",
    "    # the pdf_method should adapt to both local and\n",
    "    # hosted runtime compatibility\n",
    "    text = textract.process(pdf_path, method=pdf_method)\n",
    "\n",
    "    # queue up and reset list used to process the paper\n",
    "    temp_word_list = []\n",
    "\n",
    "    # strip new line and other markup from pdf mining\n",
    "    text = str(text).replace(\"\\\\n-\", '').replace('\\-\\n', '')\n",
    "    text = str(text).replace('\\-\\n-', '').replace('\\\\n', ' ')\n",
    "    text = str(text).replace('\\n', ' ').replace('.', '')\n",
    "    text = str(text).replace('*', \"\").replace('ISSN', '').replace('NSF', '')\n",
    "    text = str(text).replace('NIH', '').replace(\"b'\", '').replace(r\"\\r\", '')\n",
    "\n",
    "    # split by white spaces\n",
    "    temp_word_list = re.split(\"\\s+\", str(text))\n",
    "\n",
    "    # try to remove reference section by cutting off everything after\n",
    "    # the last mention of reference\n",
    "    ref = [i for i, w in enumerate(temp_word_list) if w.lower().\n",
    "           startswith('reference')]\n",
    "    try:\n",
    "        temp_word_list = temp_word_list[:(ref[-1])]\n",
    "    except Exception as e:\n",
    "        pass\n",
    "\n",
    "    # reconnect any words that got hyphenated and cut off\n",
    "    # at the end of a column\n",
    "    for i, word in enumerate(temp_word_list):\n",
    "        if re.search('[-]+$', word):\n",
    "            temp_word_list[i] = word.replace('-', '') + temp_word_list[i+1]\n",
    "            del(temp_word_list[i+1])\n",
    "\n",
    "    print('The initial list for {} has {} words.'.format(pdf_path,\n",
    "                                                         len(temp_word_list)))\n",
    "\n",
    "    # reconstruct a text string from the cleaned list, as cde's\n",
    "    # NLP works on strings\n",
    "    cleaned_text = ''\n",
    "    for word in temp_word_list:\n",
    "        cleaned_text += word\n",
    "        cleaned_text += ' '\n",
    "\n",
    "    # have cde do NLP on the string and convert the results into\n",
    "    # a list of strings\n",
    "    doc = cde.Document(cleaned_text)\n",
    "    chemicals_all = [span for span in doc.cems]\n",
    "    chem_strings = [str(word).lower().replace('\\n', ' ') for\n",
    "                    word in chemicals_all]\n",
    "\n",
    "    # remove any blanks or null values\n",
    "    chem_strings = [word for word in chem_strings if word]\n",
    "\n",
    "    # remove anything left with a backslash in it\n",
    "    chem_strings = [word for word in chem_strings if not\n",
    "                    re.search('[\\\\\\+]', word)]\n",
    "\n",
    "    print('We\\'ll attempt to resolve {} potential chemicals.'.\n",
    "          format(len(chem_strings)))\n",
    "\n",
    "    # reset lists used for processing query hits and misses\n",
    "    smiles_list = []\n",
    "    already_queried = []\n",
    "    missed_items = []\n",
    "\n",
    "    for item in chem_strings:\n",
    "\n",
    "        # keeping element symbols, such as H, C, or Na\n",
    "        # this may turn into an option\n",
    "        if item in element_symbols:\n",
    "            smiles_list.append(cirpy.resolve(item, 'smiles'))\n",
    "            print(item, smiles_list[-1])\n",
    "            continue\n",
    "\n",
    "        # adapt the regex code that leaves out short words/abbreviations\n",
    "        # to the user input above\n",
    "        if regex_number == 4:\n",
    "\n",
    "            if not re.search(\"[a-zA-Z0-9+-]{4}\", item):\n",
    "                smiles_list.append(None)\n",
    "                print('Found a word that\\'s a likely false positive: {}'.\n",
    "                      format(item))\n",
    "                missed_items.append(item)\n",
    "                continue\n",
    "\n",
    "        if regex_number == 3:\n",
    "\n",
    "            if not re.search(\"[a-zA-Z0-9+-]{3}\", item):\n",
    "                smiles_list.append(None)\n",
    "                print('Found a word that\\'s a likely false positive: {}'.\n",
    "                      format(item))\n",
    "                missed_items.append(item)\n",
    "                continue\n",
    "\n",
    "        # save time by not querying chemicals that are in the text many times\n",
    "        if item in already_queried:\n",
    "            smiles_list.append(None)\n",
    "            print('We\\'ve already queried this one: {}'.format(item))\n",
    "\n",
    "        # don't query the chemical if it's a known false positive\n",
    "        # these include author names and a few other odds and ends\n",
    "        elif item.strip('.').strip(',').lower() in false_positives:\n",
    "            smiles_list.append(None)\n",
    "            print('Found one known to be a false positive: {}'.format(item))\n",
    "\n",
    "        # if the item passes all the tests, attempt to resolve it via NIH's CIR\n",
    "        else:\n",
    "            try:\n",
    "                smiles_list.append(cirpy.resolve(item, 'smiles'))\n",
    "                print(item, smiles_list[-1])\n",
    "                time.sleep(0.21)\n",
    "\n",
    "            # except loop in here to account for internet stability issues\n",
    "            # and the like\n",
    "            except Exception as e:\n",
    "                try:\n",
    "                    print('Exception raised.  Pausing for 2 seconds and\\\n",
    "                    trying again')\n",
    "                    time.sleep(2)\n",
    "                    smiles_list.append(cirpy.resolve(item, 'smiles'))\n",
    "                    print(smiles_list[-1])\n",
    "                except Exception as e:\n",
    "                    try:\n",
    "                        print('Exception raised.  Pausing for another 2 \\\n",
    "                        seconds and trying again')\n",
    "                        time.sleep(2)\n",
    "                        smiles_list.append(cirpy.resolve(item, 'smiles'))\n",
    "                        print(smiles_list[-1])\n",
    "                    except Exception as e:\n",
    "                        try:\n",
    "                            print('Exception raised.  Pausing for one more \\\n",
    "                            stretch and trying again')\n",
    "                            time.sleep(2)\n",
    "                            smiles_list.append(cirpy.resolve(item, 'smiles'))\n",
    "                            print(smiles_list[-1])\n",
    "                        except Exception as e:\n",
    "                            print('It still raised an exception.  Here\\'s \\\n",
    "                            how far it got:')\n",
    "                            print(smiles_list)\n",
    "                            print(len(smiles_list))\n",
    "                            print('This item will be added to a list called \\\n",
    "                            missed items.')\n",
    "                            print(item)\n",
    "                            smiles_list.append('Check')\n",
    "                            missed_items.append(item)\n",
    "        already_queried.append(item)\n",
    "\n",
    "    # tidy these up into pandas dataframes and export them as csv files\n",
    "    chem_df = pd.DataFrame(zip(chem_strings, smiles_list), columns=('Name',\n",
    "                                                                    'SMILES'))\n",
    "    chem_df = chem_df.dropna()\n",
    "    chem_df.to_csv(os.path.splitext(pdf_path)[0]+'_'+datetime.today().\n",
    "                   strftime('%Y%m%d')+'_names_and_SMILES.csv')\n",
    "    if missed_items:\n",
    "        missed_df = pd.DataFrame(missed_items, columns=['Missed'])\n",
    "        missed_df.to_csv(os.path.splitext(pdf_path)[0]+'_'+datetime.today().\n",
    "                         strftime('%Y%m%d')+'_zzz_missed_items.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "executionInfo": {
     "elapsed": 67308,
     "status": "ok",
     "timestamp": 1617212265978,
     "user": {
      "displayName": "John Goeltz",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14Gj3FhUN6-o1CQ5sALSoVIN_uvhDla_H5orAz1El=s64",
      "userId": "06562502469486255027"
     },
     "user_tz": 420
    },
    "id": "9Gru4BXt12Vq"
   },
   "outputs": [],
   "source": [
    "def aggregate_csv_files():\n",
    "    # combines all results files into a single csv file\n",
    "    all_chemicals = pd.concat([pd.read_csv(filename) for filename\n",
    "                               in os.listdir(pdf_dir) if\n",
    "                               re.search('csv$', filename)])\n",
    "    all_chemicals.to_csv(datetime.today().\n",
    "                         strftime('%Y%m%d')+\"combined_csv.csv\",\n",
    "                         index=False, encoding='utf-8-sig')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "7JawBfYyYFy4"
   },
   "source": [
    "# Curate pdfs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "cellView": "form",
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 80076,
     "status": "ok",
     "timestamp": 1617212278751,
     "user": {
      "displayName": "John Goeltz",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14Gj3FhUN6-o1CQ5sALSoVIN_uvhDla_H5orAz1El=s64",
      "userId": "06562502469486255027"
     },
     "user_tz": 420
    },
    "id": "MpbNWvqBFK91",
    "outputId": "85b1b94f-5a0f-4721-f6d7-7de08d7f3f20"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The initial list for 20210309_short_doc_for_python-testing.pdf has 161 words.\n",
      "We'll attempt to resolve 2 potential chemicals.\n",
      "choline chloride [Cl-].C[N+](C)(C)CCO\n",
      "urea NC(N)=O\n"
     ]
    }
   ],
   "source": [
    "#@title ## Curator output will appear below\n",
    "\n",
    "pdf_dir = os.getcwd()\n",
    "\n",
    "pd.DataFrame(data=None, columns=('Name', 'SMILES'))\n",
    "\n",
    "assert os.path.exists(pdf_dir),\\\n",
    "    \"I did not find the directory at, \"+str(pdf_dir)\n",
    "\n",
    "os.chdir(pdf_dir)\n",
    "\n",
    "for filename in os.listdir(pdf_dir):\n",
    "    if re.search('pdf$', filename):\n",
    "        try:\n",
    "            chemicals = quick_curate(filename, pdf_method,\n",
    "                                     false_positives, regex_number)\n",
    "        except Exception as e:\n",
    "            print('An exception was raised for ' + filename)\n",
    "            print('Most likely, an error occurred when trying to\\\n",
    "            extract text from the pdf.')\n",
    "            print(e)\n",
    "\n",
    "try:\n",
    "    aggregate_csv_files()\n",
    "except Exception as e:\n",
    "    print(\"An error occurred while trying to combine the output csv files.\")\n",
    "    print(e)"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "pdf2chem_curator.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
